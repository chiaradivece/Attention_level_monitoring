{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C.C.A.S.A.: Car Concentration And Security Assistant\n",
    "Bracco Filippo & Di Vece Chiara \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stanchezza, nervosismo, distrazione e sonnolenza sono le cause di oltre il 66% degli incidenti. Questi dati allarmanti ci hanno indotto a pensare un dispositivo che possa evitare incidenti di questa natura, verificando oggettivamente che il conducente sia sempre concentrato sulla strada. Lo scopo del programma è quello di rilevare particolari condizioni  non compatibili con una guida sicura attraverso il rilevamento dei tratti del viso e, in particolar modo, degli occhi, accertandosi che lo sguardo sia rivolto verso la strada mentre il veicolo è in movimento.\n",
    "In seguito risponderà adeguatamente per richiamare all’attenzione il guidatore con avvisi acustici e visivi. \n",
    "Lo scopo principale è quello di evitare molti incidenti e poter salvare molte vite. \n",
    "\n",
    "Fatigue, nervousness, distraction and drowsiness are the causes of more than 66% of accidents. These alarming figures prompted us to devise a device that could prevent accidents of this nature by objectively verifying that the driver is always focused on the road. The aim of the programme is to detect particular conditions that are not compatible with safe driving by detecting facial features and, in particular, the eyes, making sure that the eyes are on the road while the vehicle is moving.\n",
    "It will then respond appropriately to draw the driver's attention with audible and visual warnings.\n",
    "The main aim is to avoid many accidents and save many lives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si importano le librerie:\n",
    "* **CV2**: libreria open-source per la gestione di immagini e video;\n",
    "* **NUMPY**: libreria per calcolo scientifico;\n",
    "* **PYGLET**: libreria per la gestione di immagini, video e suoni (utilizzata in questo codice solo per questi ultimi).\n",
    "\n",
    "The libraries are imported:\n",
    "* **CV2**: open-source library for image and video management;\n",
    "* **NUMPY**: library for scientific calculation;\n",
    "**PYGLET**: library for the management of images, videos and sounds (used in this code only for the latter).\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyglet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definizione costanti\n",
    "**MISURAZIONI** e **SOGLIA** sono utilizzate per discriminare lo stato di *occhi aperti* oppure *occhi chiusi*.\n",
    "\n",
    "## Constant definitions\n",
    "**MEASUREMETS** and **SHEEP** are used to discriminate the state of *eyes open* or *eyes closed*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MEASUREMETS = 10\n",
    "THRESHOLD = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variabili globali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**stato_occhi**: è un dizionario formato da:\n",
    "* la lista *'rilevamenti'*, contenente il numero di occhi rilevati nelle ultime misurazioni (la cardinalità della lista è definita dalla costante *MISURAZIONI*), iniazialmente la lista è riempita di 2 (condizione normale);\n",
    "* la variabile booleana *'occhi_chiusi'* che descrive lo stato corrente degli occhi. \n",
    "\n",
    "**eye_status**: is a dictionary consisting of:\n",
    "* the list *'detections'*, containing the number of eyes detected in the last measurements (the cardinality of the list is defined by the constant *MEASUREMENTS*), initially the list is filled with 2 (normal condition);\n",
    "* the boolean variable *'eyes_closed'* which describes the current state of the eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eye_status = {'detections': [2]*MEASUREMETS, 'closed_eyes': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) La funzione **check** ha come parametro in ingresso un intero **occhi_trovati** che rappresenta il numero di occhi rilevati in un singolo frame. Lo scopo è quello di aggiornare la variabile globale *stato_occhi*: \n",
    "* viene aggiunto il valore acquisito in coda alla lista *'rilevamenti'* del dizionario;\n",
    "* viene rimosso il primo elemento della suddetta lista (ovvero la rilevazione più vecchia tra quelle salvate);\n",
    "* viene calcolata la somma dei rilevamenti nella lista;\n",
    "* se il numero è superiore alla soglia definita, gli occhi sono aperti, quindi si assegna alla variabile *'occhi_chiusi'* del dizionario il valore *False*, *True* altrimenti.\n",
    "\n",
    "1) The **check** function has as input parameter an integer **eyes_found** representing the number of eyes detected in a single frame. The purpose is to update the global variable *eye_state*:\n",
    "* the value acquired at the end of the *'detections'* dictionary list is added;\n",
    "* the first element of this list is removed (i.e. the oldest detection among the saved ones);\n",
    "* the sum of the readings in the list is calculated;\n",
    "* if the number is higher than the defined threshold, the eyes are opened, then the dictionary variable *'eyes_closed'* is assigned the value *False*, *True* otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check(eyes_found):\n",
    "    \n",
    "    eye_status['detections'].append(eyes_found)\n",
    "    eye_status['detections'].pop(0)\n",
    "    eyes_num = sum(eye_status['detections'])\n",
    "    \n",
    "    if eyes_num > THRESHOLD:\n",
    "        eye_status['closed_eyes'] = False\n",
    "    else:\n",
    "        eye_status['closed_eyes'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) La funzione **cambia_colore** serve a cambiare il colore di pixel specifici di un'immagine. I parametri di ingresso sono l'immagine **immagine**, una lista, **pixels**, contenente le coppie di coordinate relative ai pixel il cui valore deve essere cambiato, e tre interi, **B**, **G** e **R**, che rappresentano il valore da assegnare ai pixel dell'immagine contenuti nella lista.\n",
    "\n",
    "2) The **change_color** function is used to change the colour of specific pixels in an image. The input parameters are the **image**, a list, **pixels**, containing the pairs of coordinates relating to the pixels whose value is to be changed, and three integers, **B**, **G** and **R**, representing the value to be assigned to the image pixels contained in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_color(img, pixels, B, G, R):\n",
    "    for (w,k) in pixels:\n",
    "        img[w][k] = [B, G, R]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) La funzione **draw** serve a sovrascrivere un'immagine su un'altra più grande a partire da una precisa posizione. Essa riceve in ingresso l'immagine base **img1**, la seconda immagine **img2** e due interi, **i** e **j**, che rappresentano la coordinata dell'immagine base dalla quale iniziare a copiare la seconda.\n",
    "\n",
    "3) The **draw** function is used to overwrite an image on a larger one from a specific position. It receives as input the base image **img1**, the second image **img2** and two integers, **i** and **j**, which are the coordinates of the base image from which to start copying the second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw(img1, img2, i, j):          #i = coordinata verticale, j = orizzontale\n",
    "    h,w, _ = img2.shape\n",
    "    img1[i:i+h, j:j+w] = img2[:h, :w] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) La funzione **main_face** ha come parametro in ingresso la lista **facce**. Essa contiene uno o più elementi, ognuno dei quali rappresenta una faccia rilevata nell'immagine in ingresso dalla camera; ogni elemento è una lista di quattro valori che caratterizzano la regione dell'immagine in cui è presente il volto, ovvero posizione orizzontale, posizione verticale, larghezza e altezza. La funzione restituisce i quattro parametri (**fx**, **fy**, **fw** e **fh**) della faccia con le dimensioni maggiori tra quelle contenute nella nella lista. \n",
    "\n",
    "4) The **main_face** function has as input parameter the **face** list. It contains one or more elements, each of which represents a face detected in the incoming image from the camera; each element is a list of four values that characterise the region of the image in which the face is present, i.e. horizontal position, vertical position, width and height. The function returns the four parameters (**fx**, **fy**, **fw** and **fh**) of the face with the largest dimensions among those contained in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main_face(faces):                # restituisce i parametri della faccia più estesa rilevata nell'immagine\n",
    "    fx = faces[0][0]\n",
    "    fy = faces[0][1]\n",
    "    fw = faces[0][2]\n",
    "    fh = faces[0][3]\n",
    "    \n",
    "    for [x, y, w, h] in faces:\n",
    "        if w*h > fw*fh:\n",
    "            fx = x\n",
    "            fy = y\n",
    "            fw = w\n",
    "            fh = h\n",
    "    return fx, fy, fw, fh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si caricano i file relativi alle funzioni di classificazione per faccia e occhi (materiale OpenCV).\n",
    "\n",
    "The files relating to the classification functions for face and eyes (OpenCV material) are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../Assets/lib/face.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('../Assets/lib/glasses.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si utilizza la funzione di **cv2** per consentire l'accesso alla web cam e si setta le dimensioni dell'immagine in ingresso a 320x240 pixels.\n",
    "\n",
    "You use the **cv2** function to allow access to the web cam and set the input image size to 320x240 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(0) \n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320) \n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si importano le immagini e i suoni utilizzati nel programma. \n",
    "\n",
    "The images and sounds used in the program are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "box = cv2.imread('../Assets/Img/quadro.png')\n",
    "start = cv2.imread('../Assets/Img/start.png')\n",
    "safe_drive = cv2.imread('../Assets/Img/guida_sicura.png')\n",
    "distracted_drive = cv2.imread('../Assets/Img/distrazione.png')\n",
    "danger = cv2.imread('../Assets/Img/Pericolo.png')\n",
    "triangle = cv2.imread('../Assets/Img/Allarme_sonno.png')\n",
    "yellow_triangle = cv2.imread('../Assets/Img/attenzione_giallo.png')\n",
    "open_eyes = cv2.imread('../Assets/Img/occhi_aperti.png')\n",
    "sound = pyglet.media.load('../Assets/audio/alarm.mp3')\n",
    "sound2 = pyglet.media.load('../Assets/audio/alarm2.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'immagine di base sulla quale vengono sovrascritte le altre secondarie è quella del quadro:\n",
    "\n",
    "The basic image on which the other sub-images are superimposed is that of the painting:\n",
    "\n",
    "![Quadro](../Assets/Img/quadro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si carica un file di testo contenente coppie di numeri interi che rappresentano le posizioni dei pixel del quadro da cambiare all'accensione.\n",
    "\n",
    "A text file is loaded containing pairs of integers representing the positions of the picture pixels to be changed at switch-on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixels = np.loadtxt('../Assets/files/pixels_quadro.txt', dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per creare il file si sono salvate le posizioni dei pixel del quadro con valore (70, 60, 60), che rappresenta il colore del quadro spento, in una lista, la quale è stata poi salvata su file.\n",
    "\n",
    "To create the file, the positions of the pixels of the frame with a value (70, 60), representing the colour of the off frame, were saved in a list, which was then saved to file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![File_pixels](../Assets/Img/file_img.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viene stampata sul quadro l'immagine *start* in posizione (100, 370) dell'immagine *quadro* tramite la funzione **draw**:\n",
    "\n",
    "The *start* image at position (100, 370) of the *frame* image is printed on the screen using the **draw** function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw(box, start, 100, 370)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Start](../Assets/Img/start.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si utilizzano le funzioni di **Pyglet** per la gestione degli audio: vengono creati due oggetti audio, **avviso** e  **avviso2**, che possono essere avviati e messi in pausa nel corpo del programma.\n",
    "\n",
    "The **Pyglet** functions are used to manage audio: two audio objects, **warning** and **warning2**, are created and can be started and paused in the body of the programme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "looper = pyglet.media.SourceGroup(sound.audio_format, None)          #crea looper audio (occhi chiusi)\n",
    "looper.loop = True\n",
    "looper.queue(sound)\n",
    "warning = pyglet.media.Player()\n",
    "warning.queue(looper)\n",
    "\n",
    "looper2 = pyglet.media.SourceGroup(sound2.audio_format, None)          #crea looper audio 2 (distrazione)\n",
    "looper2.loop = True\n",
    "looper2.queue(sound2)\n",
    "warning2 = pyglet.media.Player()\n",
    "warning2.queue(looper2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inizio di un ciclo **while** che stampa a schermo (tramite apposita funzione dell'ambiente) l'immagine **quadro** (*spento*) finchè su tastiera non viene premuto il tasto '**s**'. Premuto il tasto viene inserita nel quadro l'immagine **guida sicura** e viene cambiato il colore dei pixel del quadro (accensione). ![Guida sicura](../Assets/Img/guida_sicura.png)\n",
    "\n",
    "Start of a **while** cycle that prints the **panel** image (*off*) on the screen (using a special function of the environment) until the '**s**' key is pressed on the keyboard. When the key is pressed, the **safe guide** image is inserted into the screen and the colour of the screen pixels is changed (power on). safe_guide](../Assets/Img/safe_guide.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while cv2.waitKey(30) != ord('s'):\n",
    "    cv2.imshow('Car Concentration And Security Assistant', box)\n",
    "else:\n",
    "    draw(box, safe_drive, 100, 370)\n",
    "    change_color(box, pixels, 150, 210, 190)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa porzione di codice si entra in un nuovo ciclo **while** finchè non si preme su tastiera il tasto '**q**', le operazioni svolte sono:\n",
    "* si acquisisce l'immagine dalla webcam tramite la funzione **read()**;\n",
    "* si applica il filtro **BRG2GRAY** della libreria **CV2** all'immagine acquisita per poter utilizzare i classificatori;\n",
    "* si utilizza il classificatore della faccia, il quale restituisce una lista pari al numero di facce trovate e ogni elemento di questa contiene un'ulteriore lista di quattro elementi: posizione verticale, posizione orizzontale, larghezza e altezza della regione di interesse;\n",
    "* se la lista **faccia** non è vuota si cercano gli attributi della faccia rilevata più estesa (tramite la funzione **main_face** definita precedemtemente) e si riquadra l'area contenente tale volto con l'apposita funzione di **cv2**;\n",
    "* all'interno della sola regione di interesse (dove è presente la faccia) si procede alla ricerca degli occhi;\n",
    "* si invoca la funzione **check** per aggiornare lo stato degli occhi passandole in ingresso il numero di occhi rilevati;\n",
    "* ogni occhio viene riquadrato;\n",
    "* sul quadro vengono sovrascritte le immagini che segnalano la *guida sicura* e gli *occhi aperti* e si mette in pausa l'audio relativo alla distrazione **avviso2**\n",
    "\n",
    "In this portion of the code we enter a new **while** cycle until the '**q**' key is pressed on the keyboard, the operations carried out are:\n",
    "* the image from the webcam is acquired using the **read()** function;\n",
    "* apply the **BRG2GRAY** filter from the **CV2** library to the acquired image in order to use the classifiers;\n",
    "* use the face classifier, which returns a list equal to the number of faces found and each element of this list contains a further list of four elements: vertical position, horizontal position, width and height of the region of interest;\n",
    "* if the **face** list is not empty, the attributes of the largest detected face are searched for (by means of the **main_face** function defined above) and the area containing that face is re-squared with the appropriate **cv2** function;\n",
    "* within the region of interest only (where the face is present), search for the eyes;\n",
    "* the **check** function is invoked to update the eyes status by passing the number of eyes detected as input;\n",
    "* each eye is squared;\n",
    "* the picture is overwritten with images indicating *safe driving* and *eyes open* and the distraction audio is paused **warning2**.\n",
    "\n",
    "![open_eyes](../Assets/Img/occhi_aperti.png)\n",
    "\n",
    "* se, invece, la lista **faccia** è vuota viene eseguito solo il ramo **else** e si si genera un avviso di distrazione visivo (immagini sul quadro) e sonoro (si avvia audio):\n",
    "\n",
    "* if, on the other hand, the **face** list is empty, only the **else** branch is executed and a visual (images on the screen) and audio (audio starts) distraction warning is generated:\n",
    "*\n",
    "![Distraction](../Assets/Img/distrazione.png)\n",
    "\n",
    "![Yellow_triangle](../Assets/Img/attenzione_giallo.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while cv2.waitKey(30) != ord('q'):\n",
    "    ret, camera = cap.read()\n",
    "        \n",
    "    gray = cv2.cvtColor(camera, cv2.COLOR_BGR2GRAY)\n",
    "    face = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    \n",
    "    if len(face) != 0:\n",
    "        fx, fy, fw, fh = main_face(face)\n",
    "        \n",
    "        cv2.rectangle(camera,(fx,fy),(fx+fw,fy+fh),(150,210,190), 1)   \n",
    "        \n",
    "        roi_gray = gray[fy:fy+fh, fx:fx+fw]\n",
    "        roi_color = camera[fy:fy+fh, fx:fx+fw]\n",
    "        \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, maxSize=(int(fw/5),int(fh/5)), minSize=(int(fw/7),int(fh/7)))\n",
    "        \n",
    "        check(len(eyes))\n",
    "        \n",
    "        for [ex,ey,ew,eh] in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh), (150,210,190), 1)\n",
    "        \n",
    "        warning2.pause()\n",
    "        draw(box, safe_drive, 100, 370)\n",
    "        draw(box, open_eyes, 500, 455)\n",
    "        \n",
    "    else:\n",
    "        draw(box, distracted_drive, 100, 370)\n",
    "        draw(box, yellow_triangle, 500, 455)\n",
    "        warning2.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguire si verifica lo stato occhi e si aggiorna opportunamente l'output:\n",
    "* se nel dizionario **'stato_occhi'** la variabile **occhi_chiusi** è Vera si genera un avviso adeguato visivo (immagini sul quadro) e sonoro (si avvia audio):\n",
    "\n",
    "Then the eye status is checked and the output is updated accordingly:\n",
    "\n",
    "* if in the **'eye_status'** dictionary the variable **eyes_closed** is True an appropriate visual (images on the picture) and sound (audio starts) warning is generated:\n",
    "*\n",
    "![sleep](../Assets/Img/Allarme_sonno.png) ![danger](../Assets/Img/Pericolo.png)\n",
    "\n",
    "altrimenti viene messo in pausa l'audio relativo agli occhi chiusi (**avviso**).\n",
    "\n",
    "otherwise, the audio related to the closed eyes is paused (**warning**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    if eye_status['closed_eyes']:\n",
    "        warning.play()\n",
    "        draw(box, danger, 100, 370)\n",
    "        draw(box, triangle, 500, 455)\n",
    "    else:\n",
    "        warning.pause()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alla fine del ciclo si sovrappone all'immagine del quadro quella ricevuta in input dalla camera, con faccia e occhi eventualmente riquadrati, e viene mostrato a video l'immagine **quadro**.\n",
    "\n",
    "At the end of the cycle, the image received as input from the camera is superimposed on the image of the painting, with the face and eyes framed if necessary, and the **frame** image is shown on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    draw(box, camera, 235, 375)\n",
    "    cv2.imshow('Car Concentration And Security Assistant', box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Termination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al termine del ciclo precedente, avvenuto premendo da tastiera il tasto '**q**', vengono messi in pausa gli avvisi, nel caso in cui fossero in fase di *play*, e chiuse tutte le finestre aperte.\n",
    "\n",
    "At the end of the previous cycle by pressing the '**q**' key on the keyboard, the alerts are paused if they are being *played* and all open windows are closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warning.pause()\n",
    "warning2.pause()\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Website [OpenCV](http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html) per la consultazione della documentazione sulle funzioni della libreria *cv2*;\n",
    "* Download of [classificators](https://github.com/opencv/opencv/tree/master/data/haarcascades)\n",
    "* Cascade algorithms operation for the [Face Detection](http://docs.opencv.org/master/d7/d8b/tutorial_py_face_detection.html#gsc.tab=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
